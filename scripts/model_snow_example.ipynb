{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6da7f8",
   "metadata": {},
   "source": [
    "# 1. Import required libraries\n",
    "\n",
    "Install optional packages if missing (yfinance used for convenience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6143b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Install required packages from pyproject.toml dependencies\n",
    "required = [\"pandas\", \"numpy\", \"matplotlib\", \"yfinance\"]\n",
    "for pkg in required:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Add model package to path (works for shared/cloned repos)\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa96f65",
   "metadata": {},
   "source": [
    "## API Configuration\n",
    "\n",
    "Set your API keys below to enable all features. This notebook uses Anthropic (Claude) and Perplexity AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIGURE YOUR API KEYS BELOW =====\n",
    "# Replace the placeholder values with your actual API keys\n",
    "# These will be set as environment variables for the notebook session\n",
    "\n",
    "# Get your keys from:\n",
    "# - Anthropic: https://console.anthropic.com/\n",
    "# - Perplexity: https://www.perplexity.ai/settings/api\n",
    "\n",
    "ANTHROPIC_API_KEY = \"\"  # sk-ant-...\n",
    "PERPLEXITY_API_KEY = \"\"  # pplx-...\n",
    "FRED_API_KEY = \"\"  # (Optional, for FRED economic data)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "os.environ[\"PERPLEXITY_API_KEY\"] = PERPLEXITY_API_KEY\n",
    "if FRED_API_KEY:\n",
    "    os.environ[\"FRED_API_KEY\"] = FRED_API_KEY\n",
    "\n",
    "# Verify keys are set\n",
    "print(\"API Configuration:\")\n",
    "print(f\"  Anthropic: {'✓ Set' if os.getenv('ANTHROPIC_API_KEY') else '✗ Not set'}\")\n",
    "print(f\"  Perplexity: {'✓ Set' if os.getenv('PERPLEXITY_API_KEY') else '✗ Not set'}\")\n",
    "print(f\"  FRED: {'✓ Set' if os.getenv('FRED_API_KEY') else '(Optional)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2dfbe3",
   "metadata": {},
   "source": [
    "# Stage 1: Stock Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.orchestration.stock_analytics_orchestrator import StockAnalyticsOrchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205408ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate orchestrator for SNOW\n",
    "TICKER = \"SNOW\"\n",
    "orchestrator = StockAnalyticsOrchestrator(TICKER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554be5de",
   "metadata": {},
   "source": [
    "## get_technical_metrics\n",
    "Retrieve technical metrics from the `StockAnalyticsOrchestrator` and print selected values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25672565",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = orchestrator.get_technical_metrics()\n",
    "hist = orchestrator.stock_data_provider.history()\n",
    "\n",
    "print(f\"Technical Metrics for {TICKER}\")\n",
    "print(f\"Current Price: ${tech.get('current_price'):.2f}\")\n",
    "print(f\"52-Week High: ${tech.get('price_252d_high'):.2f}\")\n",
    "print(f\"52-Week Low: ${tech.get('price_252d_low'):.2f}\")\n",
    "print(f\"Historical Volatility: {tech.get('historical_volatility_annual'):.2%}\")\n",
    "print(f\"Bollinger Position: {tech.get('bollinger_position_20d_2std'):.2f}\")\n",
    "print(f\"\\nData points available: {len(hist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Price and SMA\n",
    "ax1.plot(hist.index, hist['Close'], label='Close Price', linewidth=2, color='#1f77b4')\n",
    "ax1.plot(hist.index, hist['Close'].rolling(20).mean(), label='20-Day SMA', linewidth=2, color='#ff7f0e', alpha=0.8)\n",
    "ax1.set_ylabel('Price ($)', fontsize=11)\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Volume on secondary axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.fill_between(hist.index, hist['Volume'], alpha=0.2, color='gray', label='Volume')\n",
    "ax2.set_ylabel('Volume', fontsize=11)\n",
    "ax2.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{x/1e6:.0f}M'))\n",
    "\n",
    "# Format x-axis as dates\n",
    "ax1.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "ax1.set_title(f'{TICKER} - Price, SMA 20, and Volume', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='upper left', fontsize=10)\n",
    "ax2.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76802ac1",
   "metadata": {},
   "source": [
    "## Financial Metrics\n",
    "Retrieve financial metrics and show primary accounting values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a771abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = orchestrator.get_financial_metrics()\n",
    "income_df = orchestrator.stock_data_provider.get_income_stmt()\n",
    "balance_df = orchestrator.stock_data_provider.get_balance_sheet()\n",
    "\n",
    "print(f\"Financial Metrics for {TICKER}\")\n",
    "print(f\"TTM Revenue: ${fin.get('ttm_revenue')/1e9:.2f}B\")\n",
    "print(f\"Revenue Growth YoY: {fin.get('revenue_growth_yoy'):.2%}\")\n",
    "print(f\"Gross Margin: {fin.get('gross_margin_q'):.2%}\")\n",
    "print(f\"Operating Margin: {fin.get('operating_margin_q'):.2%}\")\n",
    "print(f\"Net Profit Margin: {fin.get('net_profit_margin_q'):.2%}\")\n",
    "print(f\"ROE: {fin.get('return_on_equity_q'):.2%}\")\n",
    "print(f\"Debt/Equity: {fin.get('debt_to_equity_q'):.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'TotalRevenue' in income_df.index:\n",
    "    rev_series = pd.to_numeric(income_df.loc['TotalRevenue'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    rev_series.plot(kind='bar', ax=ax, color='#1f77b4', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Format y-axis as billions\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'${x/1e9:.1f}B'))\n",
    "    ax.set_ylabel('Revenue ($)', fontsize=11)\n",
    "    ax.set_xlabel('Quarter', fontsize=11)\n",
    "    ax.set_title(f'{TICKER} - Quarterly Total Revenue', fontsize=13, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Format x-axis labels as dates\n",
    "    if isinstance(rev_series.index[0], pd.Timestamp):\n",
    "        ax.set_xticklabels([d.strftime('%Y-%m') for d in rev_series.index], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa39e94",
   "metadata": {},
   "source": [
    "## Volume Positioning Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = orchestrator.get_volume_positioning_metrics()\n",
    "\n",
    "print(f\"Volume Positioning for {TICKER}\")\n",
    "if volume.get('average_daily_volume'):\n",
    "    print(f\"Average Daily Volume (30d): {volume.get('average_daily_volume'):,.0f}\")\n",
    "if volume.get('latest_volume'):\n",
    "    print(f\"Latest Volume: {volume.get('latest_volume'):,.0f}\")\n",
    "if volume.get('volume_trend_ratio_20d'):\n",
    "    print(f\"Volume Trend Ratio (20d): {volume.get('volume_trend_ratio_20d'):.2f}\")\n",
    "if volume.get('abnormal_volume_20d') is not None:\n",
    "    print(f\"Abnormal Volume (20d): {volume.get('abnormal_volume_20d'):.2%}\")\n",
    "if volume.get('volume_volatility_20d'):\n",
    "    print(f\"Volume Volatility (20d): {volume.get('volume_volatility_20d'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7d8ba",
   "metadata": {},
   "source": [
    "## Peer Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b709954",
   "metadata": {},
   "outputs": [],
   "source": [
    "peer_metrics = orchestrator.get_peer_metrics()\n",
    "peer_prices = orchestrator.peer_discovery_provider.get_peers_stock_data()\n",
    "\n",
    "print(f\"Peer Relative Performance (63d window)\")\n",
    "print(f\"Excess Return vs Peers: {peer_metrics.get('rolling_excess_return_63d_vs_peers'):.2%}\")\n",
    "print(f\"Outperformance Frequency: {peer_metrics.get('outperformance_frequency_63d'):.2%}\")\n",
    "print(f\"Relative Recovery Time: {peer_metrics.get('relative_recovery_time_days'):.0f} days\")\n",
    "print(f\"\\nTop Peers: {list(peer_prices.keys())[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8865bf56",
   "metadata": {},
   "source": [
    "## Stock Information & Company Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc7128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = orchestrator.stock_data_provider.get_info()\n",
    "\n",
    "# Display key company info\n",
    "key_fields = ['longName', 'sector', 'industry', 'website', 'fullTimeEmployees', \n",
    "              'marketCap', 'enterpriseValue', 'trailingPE', 'forwardPE', 'beta']\n",
    "\n",
    "print(f\"Company Information for {TICKER}\")\n",
    "for field in key_fields:\n",
    "    value = info.get(field)\n",
    "    if value:\n",
    "        if isinstance(value, (int, float)) and value > 1e6:\n",
    "            print(f\"{field}: ${value/1e9:.2f}B\" if value > 1e9 else f\"{field}: ${value/1e6:.2f}M\")\n",
    "        else:\n",
    "            print(f\"{field}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0e4e5",
   "metadata": {},
   "source": [
    "## Macro Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = orchestrator.get_macro_metrics()\n",
    "\n",
    "# Show top macro sensitivities\n",
    "macro_betas = {k: v for k, v in macro.items() if 'rolling_beta' in k}\n",
    "if macro_betas:\n",
    "    sorted_betas = sorted(macro_betas.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "    print(f\"Top Macro Economic Sensitivities (63d rolling beta) for {TICKER}:\")\n",
    "    for factor, beta in sorted_betas[:5]:\n",
    "        factor_name = factor.replace('macro_rolling_beta_63d_vs_', '')\n",
    "        print(f\"  {factor_name}: {beta:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c153975",
   "metadata": {},
   "source": [
    "## Thesis Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c23fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_ctx = orchestrator.get_thesis_context()\n",
    "\n",
    "print(f\"Thesis Quantitative Context for {TICKER}\")\n",
    "print(f\"Revenue Growth YoY: {thesis_ctx.revenue_growth_yoy:.2%}\" if thesis_ctx.revenue_growth_yoy else \"Revenue Growth YoY: N/A\")\n",
    "print(f\"Earnings Growth YoY: {thesis_ctx.earnings_growth_yoy:.2%}\" if thesis_ctx.earnings_growth_yoy else \"Earnings Growth YoY: N/A\")\n",
    "print(f\"Forward P/E: {thesis_ctx.forward_pe:.1f}x\" if thesis_ctx.forward_pe else \"Forward P/E: N/A\")\n",
    "print(f\"Analyst Target Price Upside: {thesis_ctx.analyst_target_price_upside:.2%}\" if thesis_ctx.analyst_target_price_upside else \"Analyst Target Price Upside: N/A\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUANTITATIVE CONTEXT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(thesis_ctx.to_prompt_context())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dc160d",
   "metadata": {},
   "source": [
    "# Stage 2: Thesis Engineering\n",
    "\n",
    "\n",
    "Initialize the thesis validation orchestrator and define your thesis narrative.\n",
    "Note: Stage 2 requires Anthropic API credentials (ANTHROPIC_API_KEY). If not available, the cells will show expected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d135a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.orchestration.thesis_validation_orchestrator import ThesisValidationOrchestrator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator_tv = ThesisValidationOrchestrator(TICKER)\n",
    "\n",
    "# Define sample thesis narrative and company context\n",
    "thesis_narrative = \"\"\"\n",
    "Snowflake (SNOW) will continue to outgrow the cloud data market as customers\n",
    "consolidate data workloads onto its platform, driving 20%+ revenue CAGR and\n",
    "margin expansion from scale and product mix. Management's execution\n",
    "roadmap and the stickiness of platform adoption will sustain above-market\n",
    "growth for the next 5 years.\n",
    "\"\"\"\n",
    "\n",
    "company_context = \"\"\"\n",
    "Snowflake Inc. operates a cloud-native data platform for data engineering,\n",
    "data lakes, data warehousing, data application development, and secure data\n",
    "sharing. Large enterprise customers primarily drive revenue with consumption-based pricing.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Thesis Validation Setup for {TICKER}\")\n",
    "print(f\"\\nThesis: {thesis_narrative.strip()}\")\n",
    "print(f\"\\nCompany Context: {company_context.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdeaafd",
   "metadata": {},
   "source": [
    "### Stage 2.1: Narrative Decomposition Graph (NDG)\n",
    "\n",
    "Decompose thesis into key assumptions, vulnerabilities, and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbc113",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ndg_output = orchestrator_tv.ndg.run(\n",
    "        thesis_narrative=thesis_narrative,\n",
    "        company_context=company_context,\n",
    "        quantitative_context=thesis_ctx\n",
    "    )\n",
    "    print(f\"NDG Analysis Complete for {TICKER}\")\n",
    "    print(f\"Nodes (key assumptions): {len(ndg_output.nodes)}\")\n",
    "    print(f\"Edges (relationships): {len(ndg_output.edges)}\")\n",
    "    if ndg_output.nodes:\n",
    "        print(f\"\\nSample assumptions:\")\n",
    "        for node in list(ndg_output.nodes)[:3]:\n",
    "            print(f\"  - {node.label}: {node.description[:80]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"NDG requires Anthropic API key. Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133d627",
   "metadata": {},
   "source": [
    "### Stage 2.2: Red Team (Adversarial Challenges)\n",
    "\n",
    "Generate challenges and counterarguments to stress-test the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d2856",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'ndg_output' in locals():\n",
    "        red_team_output = orchestrator_tv.red_team.run(ndg=ndg_output, company_context=company_context)\n",
    "        print(f\"Red Team Analysis Complete for {TICKER}\")\n",
    "        print(f\"Challenges generated: {len(red_team_output.challenges)}\")\n",
    "        if red_team_output.challenges:\n",
    "            print(f\"\\nSample challenges:\")\n",
    "            for challenge in red_team_output.challenges[:3]:\n",
    "                print(f\"  - {challenge.challenge[:100]}...\")\n",
    "    else:\n",
    "        print(\"Run NDG stage first to enable Red Team analysis\")\n",
    "except Exception as e:\n",
    "    print(f\"Red Team requires Anthropic API key. Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455ea26",
   "metadata": {},
   "source": [
    "### Stage 2.3: Counterfactual Scenario Engine (CRE)\n",
    "\n",
    "Generate alternative scenarios and their implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8beb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'ndg_output' in locals() and 'red_team_output' in locals():\n",
    "        cre_output = orchestrator_tv.cre.run(\n",
    "            ndg=ndg_output,\n",
    "            red_team=red_team_output,\n",
    "            company_context=company_context,\n",
    "            quantitative_context=thesis_ctx\n",
    "        )\n",
    "        print(f\"Counterfactual Scenario Analysis Complete for {TICKER}\")\n",
    "        print(f\"Scenarios generated: {len(cre_output.scenario_set.scenarios)}\")\n",
    "        if cre_output.scenario_set.scenarios:\n",
    "            print(f\"\\nScenario types:\")\n",
    "            for scenario in cre_output.scenario_set.scenarios[:3]:\n",
    "                print(f\"  - {scenario.scenario_type}: {scenario.description[:80]}...\")\n",
    "    else:\n",
    "        print(\"Run NDG and Red Team stages first to enable CRE analysis\")\n",
    "except Exception as e:\n",
    "    print(f\"CRE requires Anthropic API key. Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32ab44",
   "metadata": {},
   "source": [
    "### Stage 2.4: Financial Translation (FT)\n",
    "\n",
    "Map scenarios to financial valuations and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'cre_output' in locals():\n",
    "        ft_result = orchestrator_tv.ft.run(cre_output)\n",
    "        ft_output = ft_result.cre_output\n",
    "        print(f\"Financial Translation Complete for {TICKER}\")\n",
    "        print(f\"Valuation scenarios: {len(ft_output.scenario_results)}\")\n",
    "        if ft_output.scenario_results:\n",
    "            print(f\"\\nValuation outcomes:\")\n",
    "            for result in ft_output.scenario_results[:3]:\n",
    "                print(f\"  - Scenario: Target Price = ${result.target_price:.2f}\" if result.target_price else f\"  - Scenario analyzed\")\n",
    "    else:\n",
    "        print(\"Run CRE stage first to enable Financial Translation\")\n",
    "except Exception as e:\n",
    "    print(f\"FT requires Anthropic API key. Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa3cdb",
   "metadata": {},
   "source": [
    "### Stage 2.5: Thesis Validity Evaluation\n",
    "\n",
    "Evaluate thesis status based on rule-based assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if all(k in locals() for k in ['ft_output', 'red_team_output', 'ndg_output']):\n",
    "        validity_output = orchestrator_tv.validity_evaluator.run(ft_output, red_team_output, ndg_output)\n",
    "        print(f\"Thesis Validity Evaluation Complete for {TICKER}\")\n",
    "        print(f\"Status: {validity_output.status}\")\n",
    "        print(f\"Conviction: {validity_output.conviction_level:.2%}\" if validity_output.conviction_level else \"Conviction: N/A\")\n",
    "        if validity_output.issues:\n",
    "            print(f\"\\nKey Issues:\")\n",
    "            for issue in validity_output.issues[:3]:\n",
    "                print(f\"  - {issue}\")\n",
    "    else:\n",
    "        print(\"Run prior stages first to enable Validity Evaluation\")\n",
    "except Exception as e:\n",
    "    print(f\"Validity evaluation requires Anthropic API key. Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e5d46b",
   "metadata": {},
   "source": [
    "### Stage 2.6: Half-Life Estimation (IHLE)\n",
    "\n",
    "Estimate thesis idea half-life and monitoring cadence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6143d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'ndg_output' in locals():\n",
    "        ihle_output = orchestrator_tv.ihle.run(ndg=ndg_output, current_macro_context=None)\n",
    "        print(f\"Idea Half-Life Estimation Complete for {TICKER}\")\n",
    "        if ihle_output and ihle_output.half_life_estimate:\n",
    "            print(f\"Estimated Half-Life: {ihle_output.half_life_estimate.estimated_half_life_months} months\")\n",
    "            print(f\"Monitoring Cadence: {ihle_output.half_life_estimate.monitoring_cadence}\")\n",
    "            print(f\"Severity: {ihle_output.half_life_estimate.severity_level}\")\n",
    "        else:\n",
    "            print(\"Half-life estimate unavailable\")\n",
    "    else:\n",
    "        print(\"Run NDG stage first to enable Half-Life Estimation\")\n",
    "except Exception as e:\n",
    "    print(f\"IHLE requires Anthropic API key. Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76441f",
   "metadata": {},
   "source": [
    "### Stage 2.7: Full Pipeline (Optional)\n",
    "\n",
    "To run the complete thesis validation pipeline at once try the following cell. This orchestrates all 7 stages with proper dependency management. Individual stages above allow for inspection, paramater adjustment, and iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ef355",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final_report = orchestrator_tv.run(\n",
    "        thesis_narrative=thesis_narrative,\n",
    "        company_context=company_context,\n",
    "        quantitative_context=thesis_ctx\n",
    "    )\n",
    "    print(f'Final Status: {final_report.status}')\n",
    "    print(f'Aggregation Score: {final_report.aggregation_score:.2%}')\n",
    "except Exception as e:\n",
    "    print(f'Full pipeline requires Anthropic API key')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-research-system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
